# -*- coding: utf-8 -*-
"""Train_LSTM_Tanpa_SMOTE_NAD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z40SRcq5eGYvFha8yAmbaDsHa_pJzu7k
"""

# 1. Instalasi Library
!pip install pandas numpy scikit-learn tensorflow streamlit

# 2. Muat Data dan Eksplorasi Awal
import pandas as pd

# Muat data
df = pd.read_csv("data_gempa_aceh_2008-2023.csv")

# Tampilkan informasi dasar
print("=== Informasi Data ===")
print(df.info())
print("\n=== 5 Baris Pertama ===")
print(df.head())

# Statistik deskriptif
print("\n=== Statistik Deskriptif ===")
print(df.describe())

# Distribusi kelas
print("\n=== Distribusi Magnitudo Gempa ===")
print(df['magnitude'].value_counts())

# 3. Preprocessing Data
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np

# Handle missing values in 'magnitude' before classification
df.dropna(subset=['magnitude'], inplace=True)

# Categorize magnitude into classes (example thresholds)
# You can adjust these thresholds based on your specific needs
def classify_magnitude(magnitude):
    if magnitude < 3.0:
        return 'Minor'
    elif 3.0 <= magnitude < 5.0:
        return 'Light'
    elif 5.0 <= magnitude < 6.0:
        return 'Moderate'
    elif 6.0 <= magnitude < 7.0:
        return 'Strong'
    else:
        return 'Major'

df['class'] = df['magnitude'].apply(classify_magnitude)


# Encode label kelas
le = LabelEncoder()
df['class_encoded'] = le.fit_transform(df['class'])

# Fitur dan target
X = df[['latitude', 'longitude', 'depth', 'magnitude']]
y = df['class_encoded']

# Scaling fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

print("\n=== Dimensi Data ===")
print(f"Jumlah Fitur: {X.shape[1]}, Jumlah Sampel: {X.shape[0]}")
print(f"Data Latih: {X_train.shape[0]}, Data Uji: {X_test.shape[0]}")
print("\n=== Distribusi Kelas setelah Split ===")
print("Training data:")
unique_train, counts_train = np.unique(y_train, return_counts=True)
print(dict(zip(le.inverse_transform(unique_train), counts_train)))
print("Testing data:")
unique_test, counts_test = np.unique(y_test, return_counts=True)
print(dict(zip(le.inverse_transform(unique_test), counts_test)))

# 4. Pelatihan Model LSTM
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import classification_report, confusion_matrix

# Reshape input untuk LSTM (batch_size, timesteps=1, features)
X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

# Buat model
model = Sequential()
model.add(LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
model.add(Dense(len(le.classes_), activation='softmax'))

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
print("\n=== Ringkasan Model ===")
model.summary()

# Latih model
history = model.fit(X_train_lstm, y_train, epochs=20, batch_size=64, validation_split=0.1, verbose=1)

# Evaluasi
loss, accuracy = model.evaluate(X_test_lstm, y_test, verbose=0)
print(f"\nAkurasi Model: {accuracy*100:.2f}%")

# Laporan klasifikasi
y_pred = np.argmax(model.predict(X_test_lstm), axis=1)
print("\n=== Laporan Klasifikasi ===")
print(classification_report(y_test, y_pred, target_names=le.classes_))
print("\n=== Matriks Konfusi ===")
print(confusion_matrix(y_test, y_pred))

# Simpan model
model.save("model_gempa.keras")

import tensorflowjs as tfjs

# Muat model jika belum
from tensorflow.keras.models import load_model
model = load_model("model_gempa.keras")

# Simpan model untuk TensorFlow.js
tfjs.converters.save_keras_model(model, "tfjs_model")

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import KFold
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Load data
df = pd.read_csv('data_gempa_aceh_2008-2023.csv')

# Handle missing values in 'magnitude' before classification
df.dropna(subset=['magnitude'], inplace=True)

# Categorize magnitude into classes (example thresholds)
# You can adjust these thresholds based on your specific needs
def classify_magnitude(magnitude):
    if magnitude < 3.0:
        return 'Minor'
    elif 3.0 <= magnitude < 5.0:
        return 'Light'
    elif 5.0 <= magnitude < 6.0:
        return 'Moderate'
    elif 6.0 <= magnitude < 7.0:
        return 'Strong'
    else:
        return 'Major'

df['class'] = df['magnitude'].apply(classify_magnitude)

# Encode label kelas
le = LabelEncoder()
df['class_encoded'] = le.fit_transform(df['class'])

# Fitur dan target
X = df[['latitude', 'longitude', 'depth', 'magnitude']].values
y = df['class_encoded'].values

# Scaling fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Inisialisasi 5-Fold CV
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

fold_no = 1
accuracies = []

for train, test in kfold.split(X_scaled, y):
    print(f"\n======== Fold {fold_no} ========")

    # Split data tiap fold
    X_train, X_test = X_scaled[train], X_scaled[test]
    y_train, y_test = y[train], y[test]

    # Reshape input untuk LSTM
    X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
    X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

    # Buat model LSTM
    model = Sequential()
    model.add(LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
    model.add(Dense(len(le.classes_), activation='softmax'))

    # Compile model
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Latih model
    model.fit(X_train_lstm, y_train, epochs=20, batch_size=32, verbose=0)

    # Evaluasi model
    y_pred = np.argmax(model.predict(X_test_lstm), axis=1)

    # Akurasi tiap fold
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Akurasi Fold-{fold_no}: {accuracy*100:.2f}%")
    accuracies.append(accuracy)

    # Tampilkan laporan klasifikasi
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=le.classes_, labels=le.transform(le.classes_)))

    # Tampilkan confusion matrix
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred, labels=le.transform(le.classes_)))

    fold_no += 1

# Rata-rata akurasi
print(f"\nAkurasi rata-rata dari 5-Fold CV: {np.mean(accuracies)*100:.2f}%")



!pip install tensorflowjs

import tensorflowjs as tfjs
from tensorflow.keras.models import load_model

# Load model
model = load_model("model_gempa.keras")

# Save model for TensorFlow.js
tfjs.converters.save_keras_model(model, "tfjs_model")

import tensorflow as tf
from tensorflow.keras.models import load_model
import tensorflowjs as tfjs

# Load the model
model = load_model("model_gempa.keras")

# Save the model in TensorFlow SavedModel format
tf.saved_model.save(model, "saved_model")

# Convert the SavedModel to TensorFlow.js format
tfjs.converters.convert_tf_saved_model("saved_model", "tfjs_model_saved_model")

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import KFold
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.models import save_model
import joblib  # Untuk menyimpan LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Load data
df = pd.read_csv('data_gempa_aceh_2008-2023.csv')

# Handle missing values
df.dropna(subset=['magnitude'], inplace=True)

# Klasifikasi berdasarkan BMKG
def classify_magnitude(magnitude):
    if magnitude < 4.5:
        return 'Gempa Kecil'
    elif 4.5 <= magnitude < 5.5:
        return 'Gempa Sedang'
    else:
        return 'Gempa Besar'

df['class'] = df['magnitude'].apply(classify_magnitude)

# Encode label kelas
le = LabelEncoder()
df['class_encoded'] = le.fit_transform(df['class'])

# Fitur dan target
X = df[['latitude', 'longitude', 'depth', 'magnitude']].values
y = df['class_encoded'].values

# Scaling fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Simpan scaler untuk deployment
joblib.dump(scaler, 'scaler.pkl')

# Inisialisasi 5-Fold CV
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

fold_no = 1
accuracies = []

for train, test in kfold.split(X_scaled, y):
    print(f"\n======== Fold {fold_no} ========")

    X_train, X_test = X_scaled[train], X_scaled[test]
    y_train, y_test = y[train], y[test]

    # Reshape untuk LSTM
    X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
    X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

    # Buat model
    model = Sequential()
    model.add(LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
    model.add(Dense(len(le.classes_), activation='softmax'))

    model.compile(optimizer='adam',
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])

    # Latih model
    model.fit(X_train_lstm, y_train,
             epochs=20,
             batch_size=32,
             validation_data=(X_test_lstm, y_test),
             verbose=0)

    # Evaluasi
    y_pred = np.argmax(model.predict(X_test_lstm), axis=1)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Akurasi Fold-{fold_no}: {accuracy*100:.2f}%")
    accuracies.append(accuracy)

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred,
                               target_names=le.classes_,
                               labels=le.transform(le.classes_)))

    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred,
                          labels=le.transform(le.classes_)))

    fold_no += 1

# Rata-rata akurasi
print(f"\nAkurasi rata-rata dari 5-Fold CV: {np.mean(accuracies)*100:.2f}%")

# Simpan LabelEncoder
joblib.dump(le, 'label_encoder.pkl')

# Latih model final pada seluruh data
X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
final_model = Sequential()
final_model.add(LSTM(64, input_shape=(X_lstm.shape[1], X_lstm.shape[2])))
final_model.add(Dense(len(le.classes_), activation='softmax'))

final_model.compile(optimizer='adam',
                   loss='sparse_categorical_crossentropy',
                   metrics=['accuracy'])

# Latih model final
final_model.fit(X_lstm, y, epochs=20, batch_size=32, verbose=0)

# Simpan model final
save_model(final_model, 'gempa_model.h5')

print("\nModel final telah disimpan sebagai 'gempa_model.h5'")
print("Scaler disimpan sebagai 'scaler.pkl'")
print("LabelEncoder disimpan sebagai 'label_encoder.pkl'")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import KFold
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.models import save_model
from tensorflow.keras.callbacks import History
import joblib  # Untuk menyimpan LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Load data
df = pd.read_csv('data_gempa_aceh_2008-2023.csv')

# Handle missing values
df.dropna(subset=['magnitude'], inplace=True)

# Klasifikasi berdasarkan BMKG
def classify_magnitude(magnitude):
    if magnitude < 4.5:
        return 'Gempa Kecil'
    elif 4.5 <= magnitude < 5.5:
        return 'Gempa Sedang'
    else:
        return 'Gempa Besar'

df['class'] = df['magnitude'].apply(classify_magnitude)

# Encode label kelas
le = LabelEncoder()
df['class_encoded'] = le.fit_transform(df['class'])

# Fitur dan target
X = df[['latitude', 'longitude', 'depth', 'magnitude']].values
y = df['class_encoded'].values

# Tampilkan data setelah encoding
print("\n--- Data Setelah Encoding ---")
print(df[['magnitude', 'class', 'class_encoded']].head())

# Scaling fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Simpan scaler untuk deployment
joblib.dump(scaler, 'scaler.pkl')

# Tampilkan data sebelum dan sesudah scaling
print("\n--- Data Sebelum Scaling ---")
print(X[:5])
print("\n--- Data Setelah Scaling ---")
print(X_scaled[:5])

# Visualisasi distribusi kelas
plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='class', order=sorted(df['class'].unique()))
plt.title('Distribusi Kelas Gempa')
plt.xlabel('Kelas Gempa')
plt.ylabel('Jumlah')
plt.show()

# Matriks korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(df[['latitude', 'longitude', 'depth', 'magnitude', 'class_encoded']].corr(), annot=True, cmap='coolwarm')
plt.title('Matriks Korelasi Fitur')
plt.show()

# Inisialisasi 5-Fold CV
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

fold_no = 1
accuracies = []

for train, test in kfold.split(X_scaled, y):
    print(f"\n======== Fold {fold_no} ========")

    X_train, X_test = X_scaled[train], X_scaled[test]
    y_train, y_test = y[train], y[test]

    # Reshape untuk LSTM
    X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
    X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

    # Buat model
    model = Sequential()
    model.add(LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
    model.add(Dense(len(le.classes_), activation='softmax'))

    model.compile(optimizer='adam',
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])

    # Latih model
    history = model.fit(X_train_lstm, y_train,
                        epochs=20,
                        batch_size=32,
                        validation_data=(X_test_lstm, y_test),
                        verbose=0)

    # Evaluasi
    y_pred = np.argmax(model.predict(X_test_lstm), axis=1)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Akurasi Fold-{fold_no}: {accuracy*100:.2f}%")
    accuracies.append(accuracy)

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred,
                               target_names=le.classes_,
                               labels=le.transform(le.classes_)))

    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred,
                          labels=le.transform(le.classes_)))

    # Plot akurasi per epoch
    plt.figure(figsize=(10, 4))
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'Accuracy Fold {fold_no}')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

    fold_no += 1

# Rata-rata akurasi
print(f"\nAkurasi rata-rata dari 5-Fold CV: {np.mean(accuracies)*100:.2f}%")

# Simpan LabelEncoder
joblib.dump(le, 'label_encoder.pkl')

# Latih model final pada seluruh data
X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
final_model = Sequential()
final_model.add(LSTM(64, input_shape=(X_lstm.shape[1], X_lstm.shape[2])))
final_model.add(Dense(len(le.classes_), activation='softmax'))

final_model.compile(optimizer='adam',
                   loss='sparse_categorical_crossentropy',
                   metrics=['accuracy'])

# Latih model final
history_final = final_model.fit(X_lstm, y, epochs=20, batch_size=32, verbose=0)

# Plot akurasi model final
plt.figure(figsize=(10, 4))
plt.plot(history_final.history['accuracy'], label='Final Training Accuracy')
plt.title('Final Model Training Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Simpan model final
save_model(final_model, 'gempa_model.h5')

print("\nModel final telah disimpan sebagai 'gempa_model.h5'")
print("Scaler disimpan sebagai 'scaler.pkl'")
print("LabelEncoder disimpan sebagai 'label_encoder.pkl'")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import KFold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.models import save_model
from tensorflow.keras.callbacks import History
import joblib

# Load data
df = pd.read_csv('data_gempa_aceh_2008-2023.csv')

# Handle missing values
df.dropna(subset=['magnitude'], inplace=True)

# Klasifikasi berdasarkan BMKG
def classify_magnitude(magnitude):
    if magnitude < 4.5:
        return 'Gempa Kecil'
    elif 4.5 <= magnitude < 5.5:
        return 'Gempa Sedang'
    else:
        return 'Gempa Besar'

df['class'] = df['magnitude'].apply(classify_magnitude)

# Encode label kelas
le = LabelEncoder()
df['class_encoded'] = le.fit_transform(df['class'])

# Fitur dan target
X = df[['latitude', 'longitude', 'depth', 'magnitude']].values
y = df['class_encoded'].values

# Tampilkan data setelah encoding
print("\n--- Data Setelah Encoding ---")
print(df[['magnitude', 'class', 'class_encoded']].head())

# Scaling fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Simpan scaler untuk deployment
joblib.dump(scaler, 'scaler.pkl')

# Tampilkan data sebelum dan sesudah scaling
print("\n--- Data Sebelum Scaling ---")
print(X[:5])
print("\n--- Data Setelah Scaling ---")
print(X_scaled[:5])

# Visualisasi distribusi kelas
plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='class', order=sorted(df['class'].unique()))
plt.title('Distribusi Kelas Gempa')
plt.xlabel('Kelas Gempa')
plt.ylabel('Jumlah')
plt.show()

# Matriks korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(df[['latitude', 'longitude', 'depth', 'magnitude', 'class_encoded']].corr(), annot=True, cmap='coolwarm')
plt.title('Matriks Korelasi Fitur')
plt.show()

# Inisialisasi 5-Fold CV
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

fold_no = 1
accuracies = []

for train, test in kfold.split(X_scaled, y):
    print(f"\n======== Fold {fold_no} ========")

    X_train, X_test = X_scaled[train], X_scaled[test]
    y_train, y_test = y[train], y[test]

    # Reshape untuk LSTM
    X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
    X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

    # Buat model
    model = Sequential()
    model.add(LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
    model.add(Dense(len(le.classes_), activation='softmax'))

    model.compile(optimizer='adam',
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])

    # Latih model
    history = model.fit(X_train_lstm, y_train,
                        epochs=20,
                        batch_size=32,
                        validation_data=(X_test_lstm, y_test),
                        verbose=0)

    # Evaluasi
    y_pred = np.argmax(model.predict(X_test_lstm), axis=1)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Akurasi Fold-{fold_no}: {accuracy*100:.2f}%")
    accuracies.append(accuracy)

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred,
                               target_names=le.classes_,
                               labels=le.transform(le.classes_)))

    print("Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred, labels=le.transform(le.classes_))
    print(cm)

    # Visualisasi Confusion Matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=le.classes_, yticklabels=le.classes_)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix - Fold {fold_no}')
    plt.show()

    # Plot akurasi per epoch
    plt.figure(figsize=(10, 4))
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'Accuracy Fold {fold_no}')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

    fold_no += 1

# Rata-rata akurasi
print(f"\nAkurasi rata-rata dari 5-Fold CV: {np.mean(accuracies)*100:.2f}%")

# Simpan LabelEncoder
joblib.dump(le, 'label_encoder.pkl')

# Latih model final pada seluruh data
X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
final_model = Sequential()
final_model.add(LSTM(64, input_shape=(X_lstm.shape[1], X_lstm.shape[2])))
final_model.add(Dense(len(le.classes_), activation='softmax'))

final_model.compile(optimizer='adam',
                   loss='sparse_categorical_crossentropy',
                   metrics=['accuracy'])

# Latih model final
history_final = final_model.fit(X_lstm, y, epochs=20, batch_size=32, verbose=0)

# Plot akurasi model final
plt.figure(figsize=(10, 4))
plt.plot(history_final.history['accuracy'], label='Final Training Accuracy')
plt.title('Final Model Training Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Simpan model final
save_model(final_model, 'gempa_model.h5')

print("\nModel final telah disimpan sebagai 'gempa_model.h5'")
print("Scaler disimpan sebagai 'scaler.pkl'")
print("LabelEncoder disimpan sebagai 'label_encoder.pkl'")